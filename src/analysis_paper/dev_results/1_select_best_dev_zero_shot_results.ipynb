{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>prompt_index</th>\n",
       "      <th>split</th>\n",
       "      <th>run</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F0.5</th>\n",
       "      <th>GLEU</th>\n",
       "      <th>prompt_template</th>\n",
       "      <th>prompt_type_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>6</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>906</td>\n",
       "      <td>183</td>\n",
       "      <td>933</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.4927</td>\n",
       "      <td>0.7312</td>\n",
       "      <td>0.499937</td>\n",
       "      <td>You are a grammatical error correction tool. Y...</td>\n",
       "      <td>0-shot_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>10</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>884</td>\n",
       "      <td>175</td>\n",
       "      <td>927</td>\n",
       "      <td>0.8347</td>\n",
       "      <td>0.4881</td>\n",
       "      <td>0.7309</td>\n",
       "      <td>0.500910</td>\n",
       "      <td>Reply with a corrected version of the input se...</td>\n",
       "      <td>0-shot_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>7</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>820</td>\n",
       "      <td>169</td>\n",
       "      <td>975</td>\n",
       "      <td>0.8291</td>\n",
       "      <td>0.4568</td>\n",
       "      <td>0.7129</td>\n",
       "      <td>0.486461</td>\n",
       "      <td>You are a grammatical error correction tool. Y...</td>\n",
       "      <td>0-shot_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>6</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>1473</td>\n",
       "      <td>654</td>\n",
       "      <td>899</td>\n",
       "      <td>0.6925</td>\n",
       "      <td>0.6210</td>\n",
       "      <td>0.6769</td>\n",
       "      <td>0.574767</td>\n",
       "      <td>system: You are a grammatical error correction...</td>\n",
       "      <td>0-shot_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>7</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>1456</td>\n",
       "      <td>654</td>\n",
       "      <td>910</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.6737</td>\n",
       "      <td>0.573003</td>\n",
       "      <td>system: You are a grammatical error correction...</td>\n",
       "      <td>0-shot_7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            file                     model prompt_type  \\\n",
       "0  results_hyp_post_errantv2-3-3  facebook/opt-iml-max-30b      0-shot   \n",
       "1  results_hyp_post_errantv2-3-3  facebook/opt-iml-max-30b      0-shot   \n",
       "2  results_hyp_post_errantv2-3-3  facebook/opt-iml-max-30b      0-shot   \n",
       "3  results_hyp_post_errantv2-3-3                gpt-4-0613      0-shot   \n",
       "4  results_hyp_post_errantv2-3-3                gpt-4-0613      0-shot   \n",
       "\n",
       "   prompt_index      split  run    TP   FP   FN    Prec     Rec    F0.5  \\\n",
       "0             6  jfleg-dev    1   906  183  933  0.8320  0.4927  0.7312   \n",
       "1            10  jfleg-dev    1   884  175  927  0.8347  0.4881  0.7309   \n",
       "2             7  jfleg-dev    1   820  169  975  0.8291  0.4568  0.7129   \n",
       "3             6  jfleg-dev    1  1473  654  899  0.6925  0.6210  0.6769   \n",
       "4             7  jfleg-dev    1  1456  654  910  0.6900  0.6154  0.6737   \n",
       "\n",
       "       GLEU                                    prompt_template  \\\n",
       "0  0.499937  You are a grammatical error correction tool. Y...   \n",
       "1  0.500910  Reply with a corrected version of the input se...   \n",
       "2  0.486461  You are a grammatical error correction tool. Y...   \n",
       "3  0.574767  system: You are a grammatical error correction...   \n",
       "4  0.573003  system: You are a grammatical error correction...   \n",
       "\n",
       "  prompt_type_index  \n",
       "0          0-shot_6  \n",
       "1         0-shot_10  \n",
       "2          0-shot_7  \n",
       "3          0-shot_6  \n",
       "4          0-shot_7  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv as dataframe\n",
    "# assume 1-indexed prompt_indices\n",
    "df_zero_max = pd.read_csv('../zero_shot_dev_results.csv')\n",
    "df_zero_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return a table of max F0.5 scores for each model, filtered by split\n",
    "def get_max_f05(df, split):\n",
    "    # filter by split\n",
    "    df_split = df[df['split'] == split]\n",
    "    # group df by model and select the rows with the maximum F0.5 score\n",
    "    max_metric = 'F0.5'\n",
    "    if 'jfleg' in split:\n",
    "        max_metric = 'GLEU'\n",
    "\n",
    "    idx = df_split.groupby(['model'])[max_metric].transform(max) == df_split[max_metric]\n",
    "    df_max = df_split[idx]\n",
    "    return df_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5009095709785253"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zero_max_jfleg_temp = df_zero_max[(df_zero_max['model'] == 'facebook/opt-iml-max-30b') & (df_zero_max['split'] == 'jfleg-dev')]\n",
    "\n",
    "df_zero_max_jfleg_temp.GLEU.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['jfleg-dev', 'wibea-dev', 'fce-dev'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = df_zero_max.split.unique()\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2830585/856668224.py:10: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  idx = df_split.groupby(['model'])[max_metric].transform(max) == df_split[max_metric]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>prompt_index</th>\n",
       "      <th>split</th>\n",
       "      <th>run</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F0.5</th>\n",
       "      <th>GLEU</th>\n",
       "      <th>prompt_template</th>\n",
       "      <th>prompt_type_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>10</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>884</td>\n",
       "      <td>175</td>\n",
       "      <td>927</td>\n",
       "      <td>0.8347</td>\n",
       "      <td>0.4881</td>\n",
       "      <td>0.7309</td>\n",
       "      <td>0.500910</td>\n",
       "      <td>Reply with a corrected version of the input se...</td>\n",
       "      <td>0-shot_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>8</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>1532</td>\n",
       "      <td>713</td>\n",
       "      <td>877</td>\n",
       "      <td>0.6824</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.581980</td>\n",
       "      <td>system: Please correct the following text.  Do...</td>\n",
       "      <td>0-shot_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>google/flan-t5-xxl</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>5</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>157</td>\n",
       "      <td>1116</td>\n",
       "      <td>0.8055</td>\n",
       "      <td>0.3681</td>\n",
       "      <td>0.6508</td>\n",
       "      <td>0.459139</td>\n",
       "      <td>You are an English language teacher. A student...</td>\n",
       "      <td>0-shot_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>10</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>1526</td>\n",
       "      <td>865</td>\n",
       "      <td>866</td>\n",
       "      <td>0.6382</td>\n",
       "      <td>0.6380</td>\n",
       "      <td>0.6382</td>\n",
       "      <td>0.573593</td>\n",
       "      <td>system: Reply with a corrected version of the ...</td>\n",
       "      <td>0-shot_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>tiiuae/falcon-40b-instruct</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>6</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>1240</td>\n",
       "      <td>682</td>\n",
       "      <td>976</td>\n",
       "      <td>0.6452</td>\n",
       "      <td>0.5596</td>\n",
       "      <td>0.6260</td>\n",
       "      <td>0.540558</td>\n",
       "      <td>You are a grammatical error correction tool. Y...</td>\n",
       "      <td>0-shot_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>stabilityai/StableBeluga2</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>10</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>1510</td>\n",
       "      <td>953</td>\n",
       "      <td>964</td>\n",
       "      <td>0.6131</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.562676</td>\n",
       "      <td>### System: Reply with a corrected version of ...</td>\n",
       "      <td>0-shot_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>command</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>10</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>1286</td>\n",
       "      <td>806</td>\n",
       "      <td>997</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.5633</td>\n",
       "      <td>0.6037</td>\n",
       "      <td>0.535281</td>\n",
       "      <td>Reply with a corrected version of the input se...</td>\n",
       "      <td>0-shot_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>meta-llama/Llama-2-70b-chat-hf</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>6</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>1442</td>\n",
       "      <td>1005</td>\n",
       "      <td>940</td>\n",
       "      <td>0.5893</td>\n",
       "      <td>0.6054</td>\n",
       "      <td>0.5924</td>\n",
       "      <td>0.499830</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt; You are a grammatical error ...</td>\n",
       "      <td>0-shot_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>Writer/InstructPalmyra-20b</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>7</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>1165</td>\n",
       "      <td>905</td>\n",
       "      <td>1046</td>\n",
       "      <td>0.5628</td>\n",
       "      <td>0.5269</td>\n",
       "      <td>0.5552</td>\n",
       "      <td>0.517007</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>0-shot_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>results_hyp_post_errantv2-3-3</td>\n",
       "      <td>bigscience/bloomz-7b1</td>\n",
       "      <td>0-shot</td>\n",
       "      <td>10</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>138</td>\n",
       "      <td>1315</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.401724</td>\n",
       "      <td>Reply with a corrected version of the input se...</td>\n",
       "      <td>0-shot_10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file                           model prompt_type  \\\n",
       "1   results_hyp_post_errantv2-3-3        facebook/opt-iml-max-30b      0-shot   \n",
       "5   results_hyp_post_errantv2-3-3                      gpt-4-0613      0-shot   \n",
       "6   results_hyp_post_errantv2-3-3              google/flan-t5-xxl      0-shot   \n",
       "12  results_hyp_post_errantv2-3-3              gpt-3.5-turbo-0613      0-shot   \n",
       "15  results_hyp_post_errantv2-3-3      tiiuae/falcon-40b-instruct      0-shot   \n",
       "19  results_hyp_post_errantv2-3-3       stabilityai/StableBeluga2      0-shot   \n",
       "22  results_hyp_post_errantv2-3-3                         command      0-shot   \n",
       "25  results_hyp_post_errantv2-3-3  meta-llama/Llama-2-70b-chat-hf      0-shot   \n",
       "38  results_hyp_post_errantv2-3-3      Writer/InstructPalmyra-20b      0-shot   \n",
       "66  results_hyp_post_errantv2-3-3           bigscience/bloomz-7b1      0-shot   \n",
       "\n",
       "    prompt_index      split  run    TP    FP    FN    Prec     Rec    F0.5  \\\n",
       "1             10  jfleg-dev    1   884   175   927  0.8347  0.4881  0.7309   \n",
       "5              8  jfleg-dev    1  1532   713   877  0.6824  0.6359  0.6726   \n",
       "6              5  jfleg-dev    1   650   157  1116  0.8055  0.3681  0.6508   \n",
       "12            10  jfleg-dev    1  1526   865   866  0.6382  0.6380  0.6382   \n",
       "15             6  jfleg-dev    1  1240   682   976  0.6452  0.5596  0.6260   \n",
       "19            10  jfleg-dev    1  1510   953   964  0.6131  0.6103  0.6125   \n",
       "22            10  jfleg-dev    1  1286   806   997  0.6147  0.5633  0.6037   \n",
       "25             6  jfleg-dev    1  1442  1005   940  0.5893  0.6054  0.5924   \n",
       "38             7  jfleg-dev    1  1165   905  1046  0.5628  0.5269  0.5552   \n",
       "66            10  jfleg-dev    1   276   138  1315  0.6667  0.1735  0.4250   \n",
       "\n",
       "        GLEU                                    prompt_template  \\\n",
       "1   0.500910  Reply with a corrected version of the input se...   \n",
       "5   0.581980  system: Please correct the following text.  Do...   \n",
       "6   0.459139  You are an English language teacher. A student...   \n",
       "12  0.573593  system: Reply with a corrected version of the ...   \n",
       "15  0.540558  You are a grammatical error correction tool. Y...   \n",
       "19  0.562676  ### System: Reply with a corrected version of ...   \n",
       "22  0.535281  Reply with a corrected version of the input se...   \n",
       "25  0.499830  <s>[INST] <<SYS>> You are a grammatical error ...   \n",
       "38  0.517007  Below is an instruction that describes a task,...   \n",
       "66  0.401724  Reply with a corrected version of the input se...   \n",
       "\n",
       "   prompt_type_index  \n",
       "1          0-shot_10  \n",
       "5           0-shot_8  \n",
       "6           0-shot_5  \n",
       "12         0-shot_10  \n",
       "15          0-shot_6  \n",
       "19         0-shot_10  \n",
       "22         0-shot_10  \n",
       "25          0-shot_6  \n",
       "38          0-shot_7  \n",
       "66         0-shot_10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug\n",
    "get_max_f05(df_zero_max, 'jfleg-dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2830585/856668224.py:10: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  idx = df_split.groupby(['model'])[max_metric].transform(max) == df_split[max_metric]\n",
      "/tmp/ipykernel_2830585/3478770620.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_max_splits[split][metric] = df_max_splits[split][metric].astype(float)\n",
      "/tmp/ipykernel_2830585/3478770620.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_max_splits[split][metric] = df_max_splits[split][metric].apply(lambda x: round(x, 3))\n",
      "/tmp/ipykernel_2830585/856668224.py:10: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  idx = df_split.groupby(['model'])[max_metric].transform(max) == df_split[max_metric]\n",
      "/tmp/ipykernel_2830585/3478770620.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_max_splits[split][metric] = df_max_splits[split][metric].astype(float)\n",
      "/tmp/ipykernel_2830585/3478770620.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_max_splits[split][metric] = df_max_splits[split][metric].apply(lambda x: round(x, 3))\n",
      "/tmp/ipykernel_2830585/856668224.py:10: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  idx = df_split.groupby(['model'])[max_metric].transform(max) == df_split[max_metric]\n",
      "/tmp/ipykernel_2830585/3478770620.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_max_splits[split][metric] = df_max_splits[split][metric].astype(float)\n",
      "/tmp/ipykernel_2830585/3478770620.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_max_splits[split][metric] = df_max_splits[split][metric].apply(lambda x: round(x, 3))\n"
     ]
    }
   ],
   "source": [
    "df_max_splits = {}\n",
    "for split in splits:\n",
    "    # metric is gleu if split is jfleg\n",
    "    metric = 'F0.5' if 'jfleg' not in split else 'GLEU'\n",
    "    df_temp = get_max_f05(df_zero_max, split)\n",
    "    df_max_splits[split] = df_temp[['model', 'prompt_type_index', metric, 'Prec', 'Rec']]\n",
    "    # convert metric to float\n",
    "    df_max_splits[split][metric] = df_max_splits[split][metric].astype(float)\n",
    "    # format metric to 3 decimal places\n",
    "    df_max_splits[split][metric] = df_max_splits[split][metric].apply(lambda x: round(x, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type_index</th>\n",
       "      <th>F0.5</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0-shot_7</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>0.4775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>google/flan-t5-xxl</td>\n",
       "      <td>0-shot_6</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>0.1921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0-shot_5</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.3984</td>\n",
       "      <td>0.5045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tiiuae/falcon-40b-instruct</td>\n",
       "      <td>0-shot_7</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.4227</td>\n",
       "      <td>0.3491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>stabilityai/StableBeluga2</td>\n",
       "      <td>0-shot_7</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.4321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>0-shot_7</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.5586</td>\n",
       "      <td>0.1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>command</td>\n",
       "      <td>0-shot_6</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.3562</td>\n",
       "      <td>0.3419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>meta-llama/Llama-2-70b-chat-hf</td>\n",
       "      <td>0-shot_6</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>0.4278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Writer/InstructPalmyra-20b</td>\n",
       "      <td>0-shot_5</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.3061</td>\n",
       "      <td>0.3207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>bigscience/bloomz-7b1</td>\n",
       "      <td>0-shot_10</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.4799</td>\n",
       "      <td>0.1062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model prompt_type_index   F0.5    Prec     Rec\n",
       "49                       gpt-4-0613          0-shot_7  0.474  0.4727  0.4775\n",
       "67               google/flan-t5-xxl          0-shot_6  0.424  0.6065  0.1921\n",
       "69               gpt-3.5-turbo-0613          0-shot_5  0.416  0.3984  0.5045\n",
       "77       tiiuae/falcon-40b-instruct          0-shot_7  0.406  0.4227  0.3491\n",
       "79        stabilityai/StableBeluga2          0-shot_7  0.403  0.3964  0.4321\n",
       "84         facebook/opt-iml-max-30b          0-shot_7  0.395  0.5586  0.1820\n",
       "108                         command          0-shot_6  0.353  0.3562  0.3419\n",
       "128  meta-llama/Llama-2-70b-chat-hf          0-shot_6  0.323  0.3044  0.4278\n",
       "133      Writer/InstructPalmyra-20b          0-shot_5  0.309  0.3061  0.3207\n",
       "145           bigscience/bloomz-7b1         0-shot_10  0.282  0.4799  0.1062"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_max_splits['fce-dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = df_zero_max.model.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2830585/614959484.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_max_splits[split]['split'] = split\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type_index</th>\n",
       "      <th>GLEU</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>split</th>\n",
       "      <th>F0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>0-shot_10</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.8347</td>\n",
       "      <td>0.4881</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0-shot_8</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.6824</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>google/flan-t5-xxl</td>\n",
       "      <td>0-shot_5</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.8055</td>\n",
       "      <td>0.3681</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0-shot_10</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.6382</td>\n",
       "      <td>0.6380</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tiiuae/falcon-40b-instruct</td>\n",
       "      <td>0-shot_6</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.6452</td>\n",
       "      <td>0.5596</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model prompt_type_index   GLEU    Prec     Rec  \\\n",
       "1     facebook/opt-iml-max-30b         0-shot_10  0.501  0.8347  0.4881   \n",
       "5                   gpt-4-0613          0-shot_8  0.582  0.6824  0.6359   \n",
       "6           google/flan-t5-xxl          0-shot_5  0.459  0.8055  0.3681   \n",
       "12          gpt-3.5-turbo-0613         0-shot_10  0.574  0.6382  0.6380   \n",
       "15  tiiuae/falcon-40b-instruct          0-shot_6  0.541  0.6452  0.5596   \n",
       "\n",
       "        split  F0.5  \n",
       "1   jfleg-dev   NaN  \n",
       "5   jfleg-dev   NaN  \n",
       "6   jfleg-dev   NaN  \n",
       "12  jfleg-dev   NaN  \n",
       "15  jfleg-dev   NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each dataframe in df_max_splits, add a column with the split name\n",
    "for split in sorted(splits):\n",
    "    df_max_splits[split]['split'] = split\n",
    "\n",
    "# concatenate all dataframes from df_max_splits\n",
    "df_max_all = pd.concat(df_max_splits.values(), axis=0)\n",
    "df_max_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['jfleg-dev', 'wibea-dev', 'fce-dev'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_max_all.split.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['jfleg-dev', 'wibea-dev', 'fce-dev'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_max_all_dev = df_max_all[~df_max_all['split'].str.contains('test')]\n",
    "df_max_all_dev.split.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_all_dev.to_csv('../best_zero_shot_dev_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gec-prompting-errant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
