{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type_index</th>\n",
       "      <th>GLEU</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>split</th>\n",
       "      <th>F0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0-shot_8</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.6824</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stabilityai/StableBeluga2</td>\n",
       "      <td>0-shot_10</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.6131</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meta-llama/Llama-2-70b-chat-hf</td>\n",
       "      <td>0-shot_6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5893</td>\n",
       "      <td>0.6054</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Writer/InstructPalmyra-20b</td>\n",
       "      <td>0-shot_7</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.5628</td>\n",
       "      <td>0.5269</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>2-shot-Coyne_1</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.7768</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model prompt_type_index   GLEU    Prec     Rec  \\\n",
       "0                      gpt-4-0613          0-shot_8  0.582  0.6824  0.6359   \n",
       "1       stabilityai/StableBeluga2         0-shot_10  0.563  0.6131  0.6103   \n",
       "2  meta-llama/Llama-2-70b-chat-hf          0-shot_6  0.500  0.5893  0.6054   \n",
       "3      Writer/InstructPalmyra-20b          0-shot_7  0.517  0.5628  0.5269   \n",
       "4        facebook/opt-iml-max-30b    2-shot-Coyne_1  0.506  0.7768  0.4899   \n",
       "\n",
       "       split  F0.5  \n",
       "0  jfleg-dev   NaN  \n",
       "1  jfleg-dev   NaN  \n",
       "2  jfleg-dev   NaN  \n",
       "3  jfleg-dev   NaN  \n",
       "4  jfleg-dev   NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../best_dev_set_results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a latex row using the format: \\diagbox[dir=SW]{metric}{prompt_index}\n",
    "# where each row is a model and each column is a split\n",
    "def write_latex_row_expanded_subcript(df, model, metric, include_pre_rec=False):\n",
    "    # metric = 'F0.5' if 'jfleg' not in split else 'GLEU'\n",
    "    # get the metric value for the model from the df\n",
    "    metric_value = df[df['model'] == model][metric].values[0]\n",
    "    \n",
    "    # check if metric_value is the max value for this dataframe\n",
    "    max_metric_value = df[metric].max()\n",
    "    if metric_value == max_metric_value:\n",
    "        metric_value = '\\\\textbf{' + '{:.3f}'.format(metric_value) + '}'\n",
    "    else:\n",
    "        metric_value = '{:.3f}'.format(metric_value)\n",
    "\n",
    "    # get the prompt_index for the model from the df\n",
    "    prompt_type_index = df[df['model'] == model]['prompt_type_index'].values[0]\n",
    "\n",
    "    prompt_type = prompt_type_index.split('_')[0] \n",
    "    prompt_index = prompt_type_index.split('_')[1]\n",
    "\n",
    "    if prompt_type == '0-shot':\n",
    "        prompt_type = '0'\n",
    "        if int(prompt_index) == 10:\n",
    "            prompt_index = '\\\\textsc{coyne}'\n",
    "        elif int(prompt_index) in [6,7]:\n",
    "            prompt_index = '\\\\textsc{tool}'\n",
    "        elif int(prompt_index) == 5:\n",
    "            prompt_index = '\\\\textsc{elt}'\n",
    "    else:\n",
    "        if 'Coyne' in prompt_type:\n",
    "            prompt_type = '2'\n",
    "            prompt_index = '\\\\textsc{coyne}$^{*}$'\n",
    "        else:\n",
    "            prompt_type = prompt_type.split('-')[0]\n",
    "            if int(prompt_index) == 1:\n",
    "                prompt_index = '\\\\textsc{coyne}'\n",
    "            elif int(prompt_index) == 2:\n",
    "                prompt_index = '\\\\textsc{tool}'\n",
    "            else:\n",
    "                prompt_index = '\\\\textsc{elt}'\n",
    "\n",
    "    precision = df[df['model'] == model]['Prec'].values[0]\n",
    "    recall = df[df['model'] == model]['Rec'].values[0]\n",
    "    \n",
    "    # write the latex row\n",
    "    # $_{{{str(prompt_index)}}}$\n",
    "    return f'{precision:.3f} & {recall:.3f} & {str(metric_value)} & {prompt_type} & {str(prompt_index)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bloomz-7b1 & 0.349 & 3 & \\textsc{coyne} & 0.456 & 2 & \\textsc{coyne}$^{*}$ & 0.347 & 3 & \\textsc{coyne} \\\\\n",
      "flan-t5-xxl & 0.447 & 1 & \\textsc{tool} & 0.463 & 1 & \\textsc{tool} & 0.423 & 3 & \\textsc{tool} \\\\\n",
      "InstructPalmyra-20b & 0.341 & 2 & \\textsc{coyne} & 0.517 & 0 & \\textsc{tool} & 0.374 & 2 & \\textsc{coyne} \\\\\n",
      "opt-iml-max-30b & 0.395 & 0 & \\textsc{tool} & 0.506 & 2 & \\textsc{coyne}$^{*}$ & 0.400 & 3 & \\textsc{elt} \\\\\n",
      "falcon-40b-instruct & 0.425 & 2 & \\textsc{tool} & 0.548 & 4 & \\textsc{coyne} & 0.454 & 4 & \\textsc{tool} \\\\\n",
      "Llama-2-70b-chat-hf & 0.323 & 0 & \\textsc{tool} & 0.500 & 0 & \\textsc{tool} & 0.359 & 0 & \\textsc{tool} \\\\\n",
      "StableBeluga2 & 0.403 & 0 & \\textsc{tool} & 0.563 & 0 & \\textsc{coyne} & 0.447 & 0 & \\textsc{tool} \\\\\n",
      "command & 0.353 & 0 & \\textsc{tool} & 0.543 & 2 & \\textsc{coyne}$^{*}$ & 0.391 & 0 & \\textsc{tool} \\\\\n",
      "gpt-3.5-turbo-0613 & 0.416 & 0 & \\textsc{elt} & 0.577 & 4 & \\textsc{tool} & 0.439 & 1 & \\textsc{tool} \\\\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write the latex table\n",
    "# print(' & '.join([''] + [split for split in sorted(splits)]) + ' \\\\\\\\')\n",
    "\n",
    "model_order = [\n",
    "    'bigscience/bloomz-7b1',\n",
    "    'google/flan-t5-xxl',\n",
    "    'Writer/InstructPalmyra-20b',\n",
    "    'facebook/opt-iml-max-30b',\n",
    "    'tiiuae/falcon-40b-instruct',\n",
    "    'meta-llama/Llama-2-70b-chat-hf',\n",
    "    'stabilityai/StableBeluga2',\n",
    "    'command', \n",
    "    'gpt-3.5-turbo-0613',\n",
    "    # 'gpt-4-0613',\n",
    "    ]\n",
    "\n",
    "split_order = ['fce-dev', 'jfleg-dev', 'wibea-dev']\n",
    "\n",
    "for model in model_order:\n",
    "    if model not in df['model'].values:\n",
    "        continue\n",
    "    model_name = model.split('/')[-1]\n",
    "    row = [model_name]\n",
    "    for split in split_order:\n",
    "        df_split_temp = df[df['split'] == split]\n",
    "        metric = 'F0.5' if 'jfleg' not in split else 'GLEU'\n",
    "        row.append(write_latex_row_expanded_subcript(df_split_temp, model, metric))\n",
    "    \n",
    "    print(' & '.join(row) + ' \\\\\\\\')\n",
    "    # print('\\\\hline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print a latex table for one dataset, including the precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bloomz-7b1 & 0.508 & 0.153 & 0.347 & 3 & \\textsc{coyne} \\\\\n",
      "flan-t5-xxl & 0.623 & 0.185 & 0.423 & 3 & \\textsc{tool} \\\\\n",
      "InstructPalmyra-20b & 0.396 & 0.305 & 0.374 & 2 & \\textsc{coyne} \\\\\n",
      "opt-iml-max-30b & 0.577 & 0.180 & 0.400 & 3 & \\textsc{elt} \\\\\n",
      "falcon-40b-instruct & 0.467 & 0.407 & 0.454 & 4 & \\textsc{tool} \\\\\n",
      "Llama-2-70b-chat-hf & 0.339 & 0.469 & 0.359 & 0 & \\textsc{tool} \\\\\n",
      "StableBeluga2 & 0.442 & 0.472 & 0.447 & 0 & \\textsc{tool} \\\\\n",
      "command & 0.403 & 0.350 & 0.391 & 0 & \\textsc{tool} \\\\\n",
      "gpt-3.5-turbo-0613 & 0.422 & 0.524 & 0.439 & 1 & \\textsc{tool} \\\\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_order = [\n",
    "    'bigscience/bloomz-7b1',\n",
    "    'google/flan-t5-xxl',\n",
    "    'Writer/InstructPalmyra-20b',\n",
    "    'facebook/opt-iml-max-30b',\n",
    "    'tiiuae/falcon-40b-instruct',\n",
    "    'meta-llama/Llama-2-70b-chat-hf',\n",
    "    'stabilityai/StableBeluga2',\n",
    "    'command', \n",
    "    'gpt-3.5-turbo-0613',\n",
    "    # 'gpt-4-0613',\n",
    "    ]\n",
    "\n",
    "split_order = ['fce-dev', 'jfleg-dev', 'wibea-dev']\n",
    "split = split_order[2]\n",
    "\n",
    "for model in model_order:\n",
    "    if model not in df['model'].values:\n",
    "        continue\n",
    "    model_name = model.split('/')[-1]\n",
    "    row = [model_name]\n",
    "    \n",
    "    df_split_temp = df[df['split'] == split]\n",
    "    metric = 'F0.5' if 'jfleg' not in split else 'GLEU'\n",
    "    row.append(write_latex_row_expanded_subcript(df_split_temp, model, metric))\n",
    "    \n",
    "    print(' & '.join(row) + ' \\\\\\\\')\n",
    "    # print('\\\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full dev set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type_index</th>\n",
       "      <th>GLEU</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>split</th>\n",
       "      <th>F0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0-shot_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>0.4775</td>\n",
       "      <td>fce-dev</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0-shot_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3984</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>fce-dev</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>stabilityai/StableBeluga2</td>\n",
       "      <td>0-shot_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.4321</td>\n",
       "      <td>fce-dev</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>0-shot_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5586</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>fce-dev</td>\n",
       "      <td>0.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>command</td>\n",
       "      <td>0-shot_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3562</td>\n",
       "      <td>0.3419</td>\n",
       "      <td>fce-dev</td>\n",
       "      <td>0.353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model prompt_type_index  GLEU    Prec     Rec  \\\n",
       "20                 gpt-4-0613          0-shot_7   NaN  0.4727  0.4775   \n",
       "21         gpt-3.5-turbo-0613          0-shot_5   NaN  0.3984  0.5045   \n",
       "22  stabilityai/StableBeluga2          0-shot_7   NaN  0.3964  0.4321   \n",
       "23   facebook/opt-iml-max-30b          0-shot_7   NaN  0.5586  0.1820   \n",
       "24                    command          0-shot_6   NaN  0.3562  0.3419   \n",
       "\n",
       "      split   F0.5  \n",
       "20  fce-dev  0.474  \n",
       "21  fce-dev  0.416  \n",
       "22  fce-dev  0.403  \n",
       "23  fce-dev  0.395  \n",
       "24  fce-dev  0.353  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['split'] == 'fce-dev'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gec-prompting-xf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
