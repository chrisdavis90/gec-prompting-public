{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../few_shot_dev_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>prompt_index</th>\n",
       "      <th>split</th>\n",
       "      <th>run</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F0.5</th>\n",
       "      <th>GLEU</th>\n",
       "      <th>prompt_template</th>\n",
       "      <th>prompt_type_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>3-shot</td>\n",
       "      <td>1</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>839</td>\n",
       "      <td>192</td>\n",
       "      <td>992</td>\n",
       "      <td>0.8138</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.498200</td>\n",
       "      <td>Reply with a corrected version of the input se...</td>\n",
       "      <td>3-shot_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>2-shot-Coyne</td>\n",
       "      <td>1</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>264</td>\n",
       "      <td>957</td>\n",
       "      <td>0.7768</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.6954</td>\n",
       "      <td>0.506410</td>\n",
       "      <td>Reply with a corrected version of the input se...</td>\n",
       "      <td>2-shot-Coyne_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>3-shot</td>\n",
       "      <td>3</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>821</td>\n",
       "      <td>211</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>0.4496</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>0.494307</td>\n",
       "      <td>You are an English language teacher. A student...</td>\n",
       "      <td>3-shot_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>1-shot</td>\n",
       "      <td>3</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>710</td>\n",
       "      <td>176</td>\n",
       "      <td>1018</td>\n",
       "      <td>0.8014</td>\n",
       "      <td>0.4109</td>\n",
       "      <td>0.6734</td>\n",
       "      <td>0.470543</td>\n",
       "      <td>You are an English language teacher. A student...</td>\n",
       "      <td>1-shot_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>1-shot</td>\n",
       "      <td>1</td>\n",
       "      <td>jfleg-dev</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>128</td>\n",
       "      <td>1038</td>\n",
       "      <td>0.8327</td>\n",
       "      <td>0.3803</td>\n",
       "      <td>0.6727</td>\n",
       "      <td>0.461363</td>\n",
       "      <td>Reply with a corrected version of the input se...</td>\n",
       "      <td>1-shot_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model   prompt_type  prompt_index      split  run   TP  \\\n",
       "0  facebook/opt-iml-max-30b        3-shot             1  jfleg-dev    1  839   \n",
       "1  facebook/opt-iml-max-30b  2-shot-Coyne             1  jfleg-dev    1  919   \n",
       "2  facebook/opt-iml-max-30b        3-shot             3  jfleg-dev    1  821   \n",
       "3  facebook/opt-iml-max-30b        1-shot             3  jfleg-dev    1  710   \n",
       "4  facebook/opt-iml-max-30b        1-shot             1  jfleg-dev    1  637   \n",
       "\n",
       "    FP    FN    Prec     Rec    F0.5      GLEU  \\\n",
       "0  192   992  0.8138  0.4582  0.7045  0.498200   \n",
       "1  264   957  0.7768  0.4899  0.6954  0.506410   \n",
       "2  211  1005  0.7955  0.4496  0.6895  0.494307   \n",
       "3  176  1018  0.8014  0.4109  0.6734  0.470543   \n",
       "4  128  1038  0.8327  0.3803  0.6727  0.461363   \n",
       "\n",
       "                                     prompt_template prompt_type_index  \n",
       "0  Reply with a corrected version of the input se...          3-shot_1  \n",
       "1  Reply with a corrected version of the input se...    2-shot-Coyne_1  \n",
       "2  You are an English language teacher. A student...          3-shot_3  \n",
       "3  You are an English language teacher. A student...          1-shot_3  \n",
       "4  Reply with a corrected version of the input se...          1-shot_1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return a table of max F0.5 scores for each model, filtered by split\n",
    "def get_max_f05(df, split):\n",
    "    # filter by split\n",
    "    df_split = df[df['split'] == split]\n",
    "    # group df by model and select the rows with the maximum F0.5 score\n",
    "    max_metric = 'F0.5'\n",
    "    if 'jfleg' in split:\n",
    "        max_metric = 'GLEU'\n",
    "\n",
    "    idx = df_split.groupby(['model'])[max_metric].transform(max) == df_split[max_metric]\n",
    "    df_max = df_split[idx]\n",
    "    return df_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['jfleg-dev', 'wibea-dev', 'fce-dev'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = df.split.unique()\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2829003/856668224.py:10: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  idx = df_split.groupby(['model'])[max_metric].transform(max) == df_split[max_metric]\n",
      "/tmp/ipykernel_2829003/2860735688.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_max_splits[split][metric] = df_max_splits[split][metric].astype(float)\n",
      "/tmp/ipykernel_2829003/2860735688.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_max_splits[split][metric] = df_max_splits[split][metric].apply(lambda x: round(x, 3))\n",
      "/tmp/ipykernel_2829003/856668224.py:10: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  idx = df_split.groupby(['model'])[max_metric].transform(max) == df_split[max_metric]\n",
      "/tmp/ipykernel_2829003/2860735688.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_max_splits[split][metric] = df_max_splits[split][metric].astype(float)\n",
      "/tmp/ipykernel_2829003/2860735688.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_max_splits[split][metric] = df_max_splits[split][metric].apply(lambda x: round(x, 3))\n",
      "/tmp/ipykernel_2829003/856668224.py:10: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  idx = df_split.groupby(['model'])[max_metric].transform(max) == df_split[max_metric]\n",
      "/tmp/ipykernel_2829003/2860735688.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_max_splits[split][metric] = df_max_splits[split][metric].astype(float)\n",
      "/tmp/ipykernel_2829003/2860735688.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_max_splits[split][metric] = df_max_splits[split][metric].apply(lambda x: round(x, 3))\n"
     ]
    }
   ],
   "source": [
    "df_max_splits = {}\n",
    "for split in splits:\n",
    "    # metric is gleu if split is jfleg\n",
    "    metric = 'F0.5' if 'jfleg' not in split else 'GLEU'\n",
    "    df_temp = get_max_f05(df, split)\n",
    "    df_max_splits[split] = df_temp[['model', 'prompt_type_index', metric, 'Prec', 'Rec']]\n",
    "    # convert metric to float\n",
    "    df_max_splits[split][metric] = df_max_splits[split][metric].astype(float)\n",
    "    # format metric to 3 decimal places\n",
    "    df_max_splits[split][metric] = df_max_splits[split][metric].apply(lambda x: round(x, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type_index</th>\n",
       "      <th>GLEU</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>2-shot-Coyne_1</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.7768</td>\n",
       "      <td>0.4899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>4-shot_2</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.6377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>google/flan-t5-xxl</td>\n",
       "      <td>1-shot_2</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.7792</td>\n",
       "      <td>0.3593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>stabilityai/StableBeluga2</td>\n",
       "      <td>4-shot_1</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>0.6174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tiiuae/falcon-40b-instruct</td>\n",
       "      <td>4-shot_1</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.5521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>command</td>\n",
       "      <td>2-shot-Coyne_1</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>0.5873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Writer/InstructPalmyra-20b</td>\n",
       "      <td>2-shot-Coyne_1</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.5630</td>\n",
       "      <td>0.5554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>meta-llama/Llama-2-70b-chat-hf</td>\n",
       "      <td>2-shot_2</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.5408</td>\n",
       "      <td>0.6086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>bigscience/bloomz-7b1</td>\n",
       "      <td>2-shot-Coyne_1</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.6389</td>\n",
       "      <td>0.3588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model prompt_type_index   GLEU    Prec     Rec\n",
       "1         facebook/opt-iml-max-30b    2-shot-Coyne_1  0.506  0.7768  0.4899\n",
       "15              gpt-3.5-turbo-0613          4-shot_2  0.577  0.6356  0.6377\n",
       "21              google/flan-t5-xxl          1-shot_2  0.463  0.7792  0.3593\n",
       "26       stabilityai/StableBeluga2          4-shot_1  0.560  0.6312  0.6174\n",
       "29      tiiuae/falcon-40b-instruct          4-shot_1  0.548  0.6474  0.5521\n",
       "55                         command    2-shot-Coyne_1  0.543  0.5948  0.5873\n",
       "65      Writer/InstructPalmyra-20b    2-shot-Coyne_1  0.513  0.5630  0.5554\n",
       "72  meta-llama/Llama-2-70b-chat-hf          2-shot_2  0.469  0.5408  0.6086\n",
       "73           bigscience/bloomz-7b1    2-shot-Coyne_1  0.456  0.6389  0.3588"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_max_splits['jfleg-dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['facebook/opt-iml-max-30b', 'tiiuae/falcon-40b-instruct',\n",
       "       'gpt-3.5-turbo-0613', 'google/flan-t5-xxl',\n",
       "       'stabilityai/StableBeluga2', 'Writer/InstructPalmyra-20b',\n",
       "       'command', 'bigscience/bloomz-7b1',\n",
       "       'meta-llama/Llama-2-70b-chat-hf'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models = df.model.unique()\n",
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter df by model and split\n",
    "def filter_df(df, model, split):\n",
    "    df_model = df[df['model'] == model]\n",
    "    df_model_split = df_model[df_model['split'] == split]\n",
    "    if 'jfleg' in split:\n",
    "        # sort dataframe by GLEU\n",
    "        df_model_split = df_model_split.sort_values(by=['GLEU'], ascending=False)\n",
    "    return df_model_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a latex row using the format: \\diagbox[dir=SW]{metric}{prompt_index}\n",
    "# where each row is a model and each column is a split\n",
    "def write_latex_row_subcript(df, model, split):\n",
    "    metric = 'F0.5' if 'jfleg' not in split else 'GLEU'\n",
    "    # get the metric value for the model from the df\n",
    "    metric_value = df[df['model'] == model][metric].values[0]\n",
    "    \n",
    "    # check if metric_value is the max value for this dataframe\n",
    "    max_metric_value = df[metric].max()\n",
    "    if metric_value == max_metric_value:\n",
    "        metric_value = '\\\\textbf{' + '{:.3f}'.format(metric_value) + '}'\n",
    "    else:\n",
    "        metric_value = '{:.3f}'.format(metric_value)\n",
    "\n",
    "    # get the prompt_index for the model from the df\n",
    "    prompt_index = df[df['model'] == model]['prompt_type_index'].values[0]\n",
    "\n",
    "    if 'Coyne' in prompt_index:\n",
    "        prompt_index = '2-shot_C'\n",
    "\n",
    "    # write the latex row\n",
    "    return f'{str(metric_value)}$_{{{str(prompt_index)}}}$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a latex row using the format: \\diagbox[dir=SW]{metric}{prompt_index}\n",
    "# where each row is a model and each column is a split\n",
    "def write_latex_row_expanded_subcript(df, model, split):\n",
    "    metric = 'F0.5' if 'jfleg' not in split else 'GLEU'\n",
    "    # get the metric value for the model from the df\n",
    "    metric_value = df[df['model'] == model][metric].values[0]\n",
    "    \n",
    "    # check if metric_value is the max value for this dataframe\n",
    "    max_metric_value = df[metric].max()\n",
    "    if metric_value == max_metric_value:\n",
    "        metric_value = '\\\\textbf{' + '{:.3f}'.format(metric_value) + '}'\n",
    "    else:\n",
    "        metric_value = '{:.3f}'.format(metric_value)\n",
    "\n",
    "    # get the prompt_index for the model from the df\n",
    "    prompt_index = df[df['model'] == model]['prompt_type_index'].values[0]\n",
    "\n",
    "\n",
    "    prompt_type = prompt_index.split('_')[0] \n",
    "    prompt_index = prompt_index.split('_')[1]\n",
    "\n",
    "    if 'Coyne' in prompt_type:\n",
    "        prompt_type = '2'\n",
    "        prompt_index = '\\\\textsc{coyne}$^{*}$'\n",
    "    else:\n",
    "        prompt_type = prompt_type.split('-')[0]\n",
    "        if int(prompt_index) == 1:\n",
    "            prompt_index = '\\\\textsc{coyne}'\n",
    "        elif int(prompt_index) == 2:\n",
    "            prompt_index = '\\\\textsc{tool}'\n",
    "        else:\n",
    "            prompt_index = '\\\\textsc{elt}'\n",
    "        \n",
    "    # write the latex row\n",
    "    # $_{{{str(prompt_index)}}}$\n",
    "    return f'{str(metric_value)} & {prompt_type} & {str(prompt_index)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bloomz-7b1 & 0.349 & 3 & \\textsc{coyne} & 0.456 & 2 & \\textsc{coyne}$^{*}$ & 0.347 & 3 & \\textsc{coyne} \\\\\n",
      "flan-t5-xxl & \\textbf{0.447} & 1 & \\textsc{tool} & 0.463 & 1 & \\textsc{tool} & 0.423 & 3 & \\textsc{tool} \\\\\n",
      "InstructPalmyra-20b & 0.341 & 2 & \\textsc{coyne} & 0.513 & 2 & \\textsc{coyne}$^{*}$ & 0.374 & 2 & \\textsc{coyne} \\\\\n",
      "opt-iml-max-30b & 0.382 & 2 & \\textsc{coyne}$^{*}$ & 0.506 & 2 & \\textsc{coyne}$^{*}$ & 0.400 & 3 & \\textsc{elt} \\\\\n",
      "falcon-40b-instruct & 0.425 & 2 & \\textsc{tool} & 0.548 & 4 & \\textsc{coyne} & \\textbf{0.454} & 4 & \\textsc{tool} \\\\\n",
      "Llama-2-70b-chat-hf & 0.299 & 1 & \\textsc{coyne} & 0.469 & 2 & \\textsc{tool} & 0.330 & 2 & \\textsc{coyne} \\\\\n",
      "StableBeluga2 & 0.375 & 4 & \\textsc{coyne} & 0.560 & 4 & \\textsc{coyne} & 0.440 & 4 & \\textsc{coyne} \\\\\n",
      "command & 0.332 & 2 & \\textsc{coyne}$^{*}$ & 0.543 & 2 & \\textsc{coyne}$^{*}$ & 0.380 & 2 & \\textsc{coyne}$^{*}$ \\\\\n",
      "gpt-3.5-turbo-0613 & 0.408 & 1 & \\textsc{elt} & \\textbf{0.577} & 4 & \\textsc{tool} & 0.439 & 1 & \\textsc{tool} \\\\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write the latex table\n",
    "# print(' & '.join([''] + [split for split in sorted(splits)]) + ' \\\\\\\\')\n",
    "\n",
    "model_order = [\n",
    "    'bigscience/bloomz-7b1',\n",
    "    'google/flan-t5-xxl',\n",
    "    'Writer/InstructPalmyra-20b',\n",
    "    'facebook/opt-iml-max-30b',\n",
    "    'tiiuae/falcon-40b-instruct',\n",
    "    'meta-llama/Llama-2-70b-chat-hf',\n",
    "    'stabilityai/StableBeluga2',\n",
    "    'command', \n",
    "    'gpt-3.5-turbo-0613',\n",
    "    # 'gpt-4-0613',\n",
    "    ]\n",
    "\n",
    "splits = df.split.unique()\n",
    "\n",
    "for model in model_order:\n",
    "    if model not in all_models:\n",
    "        continue\n",
    "    model_name = model.split('/')[-1]\n",
    "    row = [model_name]\n",
    "    for split in sorted(splits):\n",
    "        row.append(write_latex_row_expanded_subcript(df_max_splits[split], model, split))\n",
    "    \n",
    "    print(' & '.join(row) + ' \\\\\\\\')\n",
    "    # print('\\\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type_index</th>\n",
       "      <th>F0.5</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tiiuae/falcon-40b-instruct</td>\n",
       "      <td>4-shot_2</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.4669</td>\n",
       "      <td>0.4075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>stabilityai/StableBeluga2</td>\n",
       "      <td>4-shot_1</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.4276</td>\n",
       "      <td>0.4964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>1-shot_2</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.4222</td>\n",
       "      <td>0.5236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>google/flan-t5-xxl</td>\n",
       "      <td>3-shot_2</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.6227</td>\n",
       "      <td>0.1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>facebook/opt-iml-max-30b</td>\n",
       "      <td>3-shot_3</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.5770</td>\n",
       "      <td>0.1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>command</td>\n",
       "      <td>2-shot-Coyne_1</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.4332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Writer/InstructPalmyra-20b</td>\n",
       "      <td>2-shot_1</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.3958</td>\n",
       "      <td>0.3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>bigscience/bloomz-7b1</td>\n",
       "      <td>3-shot_1</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.5084</td>\n",
       "      <td>0.1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>meta-llama/Llama-2-70b-chat-hf</td>\n",
       "      <td>2-shot_1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.4794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model prompt_type_index   F0.5    Prec     Rec\n",
       "110      tiiuae/falcon-40b-instruct          4-shot_2  0.454  0.4669  0.4075\n",
       "116       stabilityai/StableBeluga2          4-shot_1  0.440  0.4276  0.4964\n",
       "118              gpt-3.5-turbo-0613          1-shot_2  0.439  0.4222  0.5236\n",
       "138              google/flan-t5-xxl          3-shot_2  0.423  0.6227  0.1854\n",
       "160        facebook/opt-iml-max-30b          3-shot_3  0.400  0.5770  0.1796\n",
       "182                         command    2-shot-Coyne_1  0.380  0.3684  0.4332\n",
       "190      Writer/InstructPalmyra-20b          2-shot_1  0.374  0.3958  0.3050\n",
       "222           bigscience/bloomz-7b1          3-shot_1  0.347  0.5084  0.1529\n",
       "240  meta-llama/Llama-2-70b-chat-hf          2-shot_1  0.330  0.3063  0.4794"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_max_splits[split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2829003/2242612188.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_max_splits[split]['split'] = split\n"
     ]
    }
   ],
   "source": [
    "# for each dataframe in df_max_splits, add a column with the split name\n",
    "for split in sorted(splits):\n",
    "    df_max_splits[split]['split'] = split\n",
    "\n",
    "# concatenate all dataframes from df_max_splits\n",
    "df_max_all = pd.concat(df_max_splits.values(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_all.to_csv('../best_few_shot_dev_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gec-prompting-errant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
