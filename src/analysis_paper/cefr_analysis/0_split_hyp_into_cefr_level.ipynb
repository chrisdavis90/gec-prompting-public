{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import defaultdict\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the path to the directory this file is in\n",
    "env_path = '../../../.env'\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count lines in each .m2 cefr file\n",
    "# split model hyp file into cefr-level files\n",
    "# re-evaluate using appropriate .m2 cefr-level files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_path = os.path.join(os.environ.get('CORPORA'), 'wi+locness/m2')\n",
    "corpora_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_level = os.path.join(corpora_path, 'A.dev.auto.m2')\n",
    "b_level = os.path.join(corpora_path, 'B.dev.auto.m2')\n",
    "c_level = os.path.join(corpora_path, 'C.dev.auto.m2')\n",
    "n_level = os.path.join(corpora_path, 'N.dev.auto.m2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count sentences in a given .m2 file\n",
    "# where each sentence block is separated by a blank line\n",
    "def count_sentences(m2_file):\n",
    "    num_sentences = 0\n",
    "    with open(m2_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line == '\\n':\n",
    "                num_sentences += 1\n",
    "    return num_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cefr_sentence_count = {}\n",
    "cefr_sentence_count['A'] = count_sentences(a_level)\n",
    "cefr_sentence_count['B'] = count_sentences(b_level)\n",
    "cefr_sentence_count['C'] = count_sentences(c_level)\n",
    "cefr_sentence_count['N'] = count_sentences(n_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4384"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum cefr sentence counts\n",
    "total_sentences = 0\n",
    "for cefr_level in cefr_sentence_count:\n",
    "    total_sentences += cefr_sentence_count[cefr_level]\n",
    "total_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sentence to cefr level mapping\n",
    "# where each sentence is assigned to a cefr level\n",
    "# based on the number of sentences in each cefr level\n",
    "# and the total number of sentences\n",
    "sentence_to_cefr_level = {}\n",
    "sentence_index = 0\n",
    "for cefr_level in cefr_sentence_count:\n",
    "    for i in range(cefr_sentence_count[cefr_level]):\n",
    "        sentence_to_cefr_level[sentence_index] = cefr_level\n",
    "        sentence_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_to_cefr_level[1036]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2327"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1037 + 1290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read best results\n",
    "df = pd.read_csv('../best_dev_set_results.csv')\n",
    "# select only rows where split == 'wibea-dev'\n",
    "df = df[df['split'] == 'wibea-dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type_index</th>\n",
       "      <th>GLEU</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>split</th>\n",
       "      <th>F0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0-shot_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.5083</td>\n",
       "      <td>wibea-dev</td>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stabilityai/StableBeluga2</td>\n",
       "      <td>0-shot_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4416</td>\n",
       "      <td>0.4723</td>\n",
       "      <td>wibea-dev</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>command</td>\n",
       "      <td>0-shot_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4029</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>wibea-dev</td>\n",
       "      <td>0.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>meta-llama/Llama-2-70b-chat-hf</td>\n",
       "      <td>0-shot_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>wibea-dev</td>\n",
       "      <td>0.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tiiuae/falcon-40b-instruct</td>\n",
       "      <td>4-shot_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4669</td>\n",
       "      <td>0.4075</td>\n",
       "      <td>wibea-dev</td>\n",
       "      <td>0.454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model prompt_type_index  GLEU    Prec     Rec  \\\n",
       "10                      gpt-4-0613          0-shot_6   NaN  0.5107  0.5083   \n",
       "11       stabilityai/StableBeluga2          0-shot_7   NaN  0.4416  0.4723   \n",
       "12                         command          0-shot_6   NaN  0.4029  0.3497   \n",
       "13  meta-llama/Llama-2-70b-chat-hf          0-shot_6   NaN  0.3394  0.4690   \n",
       "14      tiiuae/falcon-40b-instruct          4-shot_2   NaN  0.4669  0.4075   \n",
       "\n",
       "        split   F0.5  \n",
       "10  wibea-dev  0.510  \n",
       "11  wibea-dev  0.447  \n",
       "12  wibea-dev  0.391  \n",
       "13  wibea-dev  0.359  \n",
       "14  wibea-dev  0.454  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0-shot_6', '0-shot_7', '4-shot_2', '1-shot_2', '3-shot_2',\n",
       "       '3-shot_3', '2-shot_1', '3-shot_1'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prompt_type_index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_source_model_template = 'wibea_dataset_dev_{model}_{prompt_type}_{prompt_index}_beams=1_temp=0.1_topk=50_topp=1.0'\n",
    "gpt_model_template = 'wibea_dataset_dev_{model}_{prompt_type}_{prompt_index}_temp=0.1_topp=1.0'\n",
    "cohere_model_template = 'wibea_dataset_dev_{model}_{prompt_type}_{prompt_index}_temp=0.1_topk=50_topp=1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath('../../../paper_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_base_path = os.path.abspath('../../../paper_output/output_few_shot_dev')\n",
    "zero_shot_base_path = os.path.abspath('../../../paper_output/output_zero_shot_dev')\n",
    "\n",
    "model_paths = []\n",
    "for index, row in df.iterrows():\n",
    "    model = row['model'].split('/')[-1]\n",
    "\n",
    "    template = open_source_model_template\n",
    "    if 'gpt' in model:\n",
    "        template = gpt_model_template\n",
    "    elif 'command' in model:\n",
    "        template = cohere_model_template\n",
    "\n",
    "    prompt_type_index = row['prompt_type_index']\n",
    "    prompt_type, prompt_index = prompt_type_index.split('_')\n",
    "\n",
    "    prompt_type = prompt_type.replace('-', '_')\n",
    "\n",
    "    # need to reduce prompt_index by 1 when mapping to file paths\n",
    "    # yeah I know.\n",
    "    prompt_index = int(prompt_index) - 1\n",
    "\n",
    "    base_path = few_shot_base_path\n",
    "    if prompt_type == '0_shot':\n",
    "        prompt_type = 'zero_shot'\n",
    "        base_path = zero_shot_base_path\n",
    "\n",
    "    model_path = os.path.join(\n",
    "        base_path,\n",
    "        template.format(model=model, prompt_type=prompt_type, prompt_index=prompt_index),\n",
    "        \"run_1\",)\n",
    "    model_paths.append(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model_paths:\n",
    "    print(m)\n",
    "    assert os.path.exists(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_m2_file = os.path.join(model_paths[0], 'hyp_post_errantv2-3-3.m2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in hyp file\n",
    "hyp_cefr_sentences = defaultdict(list)\n",
    "sentence_i = 0\n",
    "with open(hyp_m2_file, 'r') as f:\n",
    "    sentence_block = []\n",
    "    for line in f:\n",
    "        if line == '\\n':\n",
    "            cefr_level_i = sentence_to_cefr_level[sentence_i]\n",
    "            hyp_cefr_sentences[cefr_level_i].append(list(sentence_block))\n",
    "            sentence_block = []\n",
    "            sentence_i += 1\n",
    "        else:\n",
    "            sentence_block.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 1037\n",
      "B: 1290\n",
      "C: 1069\n",
      "N: 988\n"
     ]
    }
   ],
   "source": [
    "# print sentence count in hyp_cefr_sentences in each cefr level\n",
    "for cefr_level in hyp_cefr_sentences:\n",
    "    print(f'{cefr_level}: {len(hyp_cefr_sentences[cefr_level])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 1037\n",
      "B: 1290\n",
      "C: 1069\n",
      "N: 988\n"
     ]
    }
   ],
   "source": [
    "# print sentence count in cefr_sentence_count\n",
    "for cefr_level in cefr_sentence_count:\n",
    "    print(f'{cefr_level}: {cefr_sentence_count[cefr_level]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 23.654197080291972\n",
      "B: 29.425182481751825\n",
      "C: 24.384124087591243\n",
      "N: 22.536496350364963\n"
     ]
    }
   ],
   "source": [
    "# calculate percentage of each cefr level as a percentage of the total\n",
    "for cefr_level in cefr_sentence_count:\n",
    "    print(f'{cefr_level}: {cefr_sentence_count[cefr_level] / total_sentences * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for cefr_level in hyp_cefr_sentences:\n",
    "    cefr_level_file = os.path.join(model_paths[0], f'hyp_post_{cefr_level}.m2')\n",
    "    # write sentences to cefr level file\n",
    "    with open(cefr_level_file, 'w') as f:\n",
    "        for sentence_block in hyp_cefr_sentences[cefr_level]:\n",
    "            for line in sentence_block:\n",
    "                f.write(line)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_hyp_into_cefr_hyp(model_path):\n",
    "    m2_file = os.path.join(model_path, 'hyp_post_errantv2-3-3.m2')\n",
    "\n",
    "    # read in hyp file\n",
    "    hyp_cefr_sentences = defaultdict(list)\n",
    "    sentence_i = 0\n",
    "    with open(m2_file, 'r') as f:\n",
    "        sentence_block = []\n",
    "        for line in f:\n",
    "            if line == '\\n':\n",
    "                cefr_level_i = sentence_to_cefr_level[sentence_i]\n",
    "                hyp_cefr_sentences[cefr_level_i].append(list(sentence_block))\n",
    "                sentence_block = []\n",
    "                sentence_i += 1\n",
    "            else:\n",
    "                sentence_block.append(line)\n",
    "    \n",
    "    for cefr_level in hyp_cefr_sentences:\n",
    "        cefr_level_file = os.path.join(model_path, f'hyp_post_{cefr_level}.m2')\n",
    "        # write sentences to cefr level file\n",
    "        with open(cefr_level_file, 'w') as f:\n",
    "            for sentence_block in hyp_cefr_sentences[cefr_level]:\n",
    "                for line in sentence_block:\n",
    "                    f.write(line)\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wibea_dataset_dev_gpt-4-0613_zero_shot_5_temp=0.1_topp=1.0\n",
      "wibea_dataset_dev_StableBeluga2_zero_shot_6_beams=1_temp=0.1_topk=50_topp=1.0\n",
      "wibea_dataset_dev_command_zero_shot_5_temp=0.1_topk=50_topp=1.0\n",
      "wibea_dataset_dev_Llama-2-70b-chat-hf_zero_shot_5_beams=1_temp=0.1_topk=50_topp=1.0\n",
      "wibea_dataset_dev_falcon-40b-instruct_4_shot_1_beams=1_temp=0.1_topk=50_topp=1.0\n",
      "wibea_dataset_dev_gpt-3.5-turbo-0613_1_shot_1_temp=0.1_topp=1.0\n",
      "wibea_dataset_dev_flan-t5-xxl_3_shot_1_beams=1_temp=0.1_topk=50_topp=1.0\n",
      "wibea_dataset_dev_opt-iml-max-30b_3_shot_2_beams=1_temp=0.1_topk=50_topp=1.0\n",
      "wibea_dataset_dev_InstructPalmyra-20b_2_shot_0_beams=1_temp=0.1_topk=50_topp=1.0\n",
      "wibea_dataset_dev_bloomz-7b1_3_shot_0_beams=1_temp=0.1_topk=50_topp=1.0\n"
     ]
    }
   ],
   "source": [
    "for mp in model_paths:\n",
    "    print(os.path.basename(os.path.dirname(mp)))\n",
    "    split_hyp_into_cefr_hyp(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gec-prompting-errant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
